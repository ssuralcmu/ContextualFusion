No protocol specified
No protocol specified
2024-02-16 10:33:16,874 - mmdet3d - INFO - Config:
seed = 0
deterministic = False
checkpoint_config = dict(interval=1, max_keep_ckpts=50)
log_config = dict(
    interval=100,
    hooks=[dict(type='TextLoggerHook'),
           dict(type='TensorboardLoggerHook')])
load_from = 'runs/train_mapseg_run_11+20_epochs/epoch_20.pth'
resume_from = None
cudnn_benchmark = False
fp16 = dict(loss_scale=dict(growth_interval=2000))
max_epochs = 20
runner = dict(type='CustomEpochBasedRunner', max_epochs=20)
dataset_type = 'NuScenesDataset'
dataset_root = 'data/nuscenes/'
gt_paste_stop_epoch = -1
reduce_beams = 32
load_dim = 5
use_dim = 5
load_augmented = None
point_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]
voxel_size = [0.1, 0.1, 0.2]
image_size = [256, 704]
augment2d = dict(
    resize=[[0.38, 0.55], [0.48, 0.48]],
    rotate=[-5.4, 5.4],
    gridmask=dict(prob=0.0, fixed_prob=True))
augment3d = dict(
    scale=[0.9, 1.1], rotate=[-0.78539816, 0.78539816], translate=0.5)
object_classes = [
    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',
    'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
]
map_classes = [
    'drivable_area', 'ped_crossing', 'walkway', 'stop_line', 'carpark_area',
    'divider'
]
input_modality = dict(
    use_lidar=True,
    use_camera=True,
    use_radar=False,
    use_map=False,
    use_external=False)
train_pipeline = [
    dict(type='LoadMultiViewImageFromFiles', to_float32=True),
    dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=5,
        reduce_beams=32,
        load_augmented=None),
    dict(
        type='LoadPointsFromMultiSweeps',
        sweeps_num=9,
        load_dim=5,
        use_dim=5,
        reduce_beams=32,
        pad_empty_sweeps=True,
        remove_close=True,
        load_augmented=None),
    dict(
        type='LoadAnnotations3D',
        with_bbox_3d=True,
        with_label_3d=True,
        with_attr_label=False),
    dict(
        type='ObjectPaste',
        stop_epoch=-1,
        db_sampler=dict(
            dataset_root='data/nuscenes/',
            info_path='data/nuscenes/nuscenes_dbinfos_train.pkl',
            rate=1.0,
            prepare=dict(
                filter_by_difficulty=[-1],
                filter_by_min_points=dict(
                    car=5,
                    truck=5,
                    bus=5,
                    trailer=5,
                    construction_vehicle=5,
                    traffic_cone=5,
                    barrier=5,
                    motorcycle=5,
                    bicycle=5,
                    pedestrian=5)),
            classes=[
                'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                'traffic_cone'
            ],
            sample_groups=dict(
                car=2,
                truck=3,
                construction_vehicle=7,
                bus=4,
                trailer=6,
                barrier=2,
                motorcycle=6,
                bicycle=6,
                pedestrian=2,
                traffic_cone=2),
            points_loader=dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=5,
                use_dim=5,
                reduce_beams=32))),
    dict(
        type='ImageAug3D',
        final_dim=[256, 704],
        resize_lim=[0.38, 0.55],
        bot_pct_lim=[0.0, 0.0],
        rot_lim=[-5.4, 5.4],
        rand_flip=True,
        is_train=True),
    dict(
        type='GlobalRotScaleTrans',
        resize_lim=[0.9, 1.1],
        rot_lim=[-0.78539816, 0.78539816],
        trans_lim=0.5,
        is_train=True),
    dict(
        type='LoadBEVSegmentation',
        dataset_root='data/nuscenes/',
        xbound=[-50.0, 50.0, 0.1],
        ybound=[-50.0, 50.0, 0.1],
        classes=[
            'drivable_area', 'ped_crossing', 'walkway', 'stop_line',
            'carpark_area', 'divider'
        ]),
    dict(type='RandomFlip3D'),
    dict(
        type='PointsRangeFilter',
        point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]),
    dict(
        type='ObjectRangeFilter',
        point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]),
    dict(
        type='ObjectNameFilter',
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ]),
    dict(
        type='ImageNormalize',
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]),
    dict(
        type='GridMask',
        use_h=True,
        use_w=True,
        max_epoch=20,
        rotate=1,
        offset=False,
        ratio=0.5,
        mode=1,
        prob=0.0,
        fixed_prob=True),
    dict(type='PointShuffle'),
    dict(
        type='DefaultFormatBundle3D',
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ]),
    dict(
        type='Collect3D',
        keys=['img', 'points', 'gt_bboxes_3d', 'gt_labels_3d', 'gt_masks_bev'],
        meta_keys=[
            'camera_intrinsics', 'camera2ego', 'lidar2ego', 'lidar2camera',
            'camera2lidar', 'lidar2image', 'img_aug_matrix', 'lidar_aug_matrix'
        ])
]
test_pipeline = [
    dict(type='LoadMultiViewImageFromFiles', to_float32=True),
    dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=5,
        reduce_beams=32,
        load_augmented=None),
    dict(
        type='LoadPointsFromMultiSweeps',
        sweeps_num=9,
        load_dim=5,
        use_dim=5,
        reduce_beams=32,
        pad_empty_sweeps=True,
        remove_close=True,
        load_augmented=None),
    dict(
        type='LoadAnnotations3D',
        with_bbox_3d=True,
        with_label_3d=True,
        with_attr_label=False),
    dict(
        type='ImageAug3D',
        final_dim=[256, 704],
        resize_lim=[0.48, 0.48],
        bot_pct_lim=[0.0, 0.0],
        rot_lim=[0.0, 0.0],
        rand_flip=False,
        is_train=False),
    dict(
        type='GlobalRotScaleTrans',
        resize_lim=[1.0, 1.0],
        rot_lim=[0.0, 0.0],
        trans_lim=0.0,
        is_train=False),
    dict(
        type='LoadBEVSegmentation',
        dataset_root='data/nuscenes/',
        xbound=[-50.0, 50.0, 0.1],
        ybound=[-50.0, 50.0, 0.1],
        classes=[
            'drivable_area', 'ped_crossing', 'walkway', 'stop_line',
            'carpark_area', 'divider'
        ]),
    dict(
        type='PointsRangeFilter',
        point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]),
    dict(
        type='ImageNormalize',
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]),
    dict(
        type='DefaultFormatBundle3D',
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ]),
    dict(
        type='Collect3D',
        keys=['img', 'points', 'gt_bboxes_3d', 'gt_labels_3d', 'gt_masks_bev'],
        meta_keys=[
            'camera_intrinsics', 'camera2ego', 'lidar2ego', 'lidar2camera',
            'camera2lidar', 'lidar2image', 'img_aug_matrix', 'lidar_aug_matrix'
        ])
]
data = dict(
    samples_per_gpu=4,
    workers_per_gpu=4,
    train=dict(
        type='CBGSDataset',
        dataset=dict(
            type='NuScenesDataset',
            dataset_root='data/nuscenes/',
            ann_file='data/nuscenes/nuscenes_infos_train.pkl',
            pipeline=[
                dict(type='LoadMultiViewImageFromFiles', to_float32=True),
                dict(
                    type='LoadPointsFromFile',
                    coord_type='LIDAR',
                    load_dim=5,
                    use_dim=5,
                    reduce_beams=32,
                    load_augmented=None),
                dict(
                    type='LoadPointsFromMultiSweeps',
                    sweeps_num=9,
                    load_dim=5,
                    use_dim=5,
                    reduce_beams=32,
                    pad_empty_sweeps=True,
                    remove_close=True,
                    load_augmented=None),
                dict(
                    type='LoadAnnotations3D',
                    with_bbox_3d=True,
                    with_label_3d=True,
                    with_attr_label=False),
                dict(
                    type='ObjectPaste',
                    stop_epoch=-1,
                    db_sampler=dict(
                        dataset_root='data/nuscenes/',
                        info_path='data/nuscenes/nuscenes_dbinfos_train.pkl',
                        rate=1.0,
                        prepare=dict(
                            filter_by_difficulty=[-1],
                            filter_by_min_points=dict(
                                car=5,
                                truck=5,
                                bus=5,
                                trailer=5,
                                construction_vehicle=5,
                                traffic_cone=5,
                                barrier=5,
                                motorcycle=5,
                                bicycle=5,
                                pedestrian=5)),
                        classes=[
                            'car', 'truck', 'construction_vehicle', 'bus',
                            'trailer', 'barrier', 'motorcycle', 'bicycle',
                            'pedestrian', 'traffic_cone'
                        ],
                        sample_groups=dict(
                            car=2,
                            truck=3,
                            construction_vehicle=7,
                            bus=4,
                            trailer=6,
                            barrier=2,
                            motorcycle=6,
                            bicycle=6,
                            pedestrian=2,
                            traffic_cone=2),
                        points_loader=dict(
                            type='LoadPointsFromFile',
                            coord_type='LIDAR',
                            load_dim=5,
                            use_dim=5,
                            reduce_beams=32))),
                dict(
                    type='ImageAug3D',
                    final_dim=[256, 704],
                    resize_lim=[0.38, 0.55],
                    bot_pct_lim=[0.0, 0.0],
                    rot_lim=[-5.4, 5.4],
                    rand_flip=True,
                    is_train=True),
                dict(
                    type='GlobalRotScaleTrans',
                    resize_lim=[0.9, 1.1],
                    rot_lim=[-0.78539816, 0.78539816],
                    trans_lim=0.5,
                    is_train=True),
                dict(
                    type='LoadBEVSegmentation',
                    dataset_root='data/nuscenes/',
                    xbound=[-50.0, 50.0, 0.1],
                    ybound=[-50.0, 50.0, 0.1],
                    classes=[
                        'drivable_area', 'ped_crossing', 'walkway',
                        'stop_line', 'carpark_area', 'divider'
                    ]),
                dict(type='RandomFlip3D'),
                dict(
                    type='PointsRangeFilter',
                    point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]),
                dict(
                    type='ObjectRangeFilter',
                    point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]),
                dict(
                    type='ObjectNameFilter',
                    classes=[
                        'car', 'truck', 'construction_vehicle', 'bus',
                        'trailer', 'barrier', 'motorcycle', 'bicycle',
                        'pedestrian', 'traffic_cone'
                    ]),
                dict(
                    type='ImageNormalize',
                    mean=[0.485, 0.456, 0.406],
                    std=[0.229, 0.224, 0.225]),
                dict(
                    type='GridMask',
                    use_h=True,
                    use_w=True,
                    max_epoch=20,
                    rotate=1,
                    offset=False,
                    ratio=0.5,
                    mode=1,
                    prob=0.0,
                    fixed_prob=True),
                dict(type='PointShuffle'),
                dict(
                    type='DefaultFormatBundle3D',
                    classes=[
                        'car', 'truck', 'construction_vehicle', 'bus',
                        'trailer', 'barrier', 'motorcycle', 'bicycle',
                        'pedestrian', 'traffic_cone'
                    ]),
                dict(
                    type='Collect3D',
                    keys=[
                        'img', 'points', 'gt_bboxes_3d', 'gt_labels_3d',
                        'gt_masks_bev'
                    ],
                    meta_keys=[
                        'camera_intrinsics', 'camera2ego', 'lidar2ego',
                        'lidar2camera', 'camera2lidar', 'lidar2image',
                        'img_aug_matrix', 'lidar_aug_matrix'
                    ])
            ],
            object_classes=[
                'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                'traffic_cone'
            ],
            map_classes=[
                'drivable_area', 'ped_crossing', 'walkway', 'stop_line',
                'carpark_area', 'divider'
            ],
            modality=dict(
                use_lidar=True,
                use_camera=True,
                use_radar=False,
                use_map=False,
                use_external=False),
            test_mode=False,
            use_valid_flag=True,
            box_type_3d='LiDAR')),
    val=dict(
        type='NuScenesDataset',
        dataset_root='data/nuscenes/',
        ann_file='data/nuscenes/nuscenes_infos_val.pkl',
        pipeline=[
            dict(type='LoadMultiViewImageFromFiles', to_float32=True),
            dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=5,
                use_dim=5,
                reduce_beams=32,
                load_augmented=None),
            dict(
                type='LoadPointsFromMultiSweeps',
                sweeps_num=9,
                load_dim=5,
                use_dim=5,
                reduce_beams=32,
                pad_empty_sweeps=True,
                remove_close=True,
                load_augmented=None),
            dict(
                type='LoadAnnotations3D',
                with_bbox_3d=True,
                with_label_3d=True,
                with_attr_label=False),
            dict(
                type='ImageAug3D',
                final_dim=[256, 704],
                resize_lim=[0.48, 0.48],
                bot_pct_lim=[0.0, 0.0],
                rot_lim=[0.0, 0.0],
                rand_flip=False,
                is_train=False),
            dict(
                type='GlobalRotScaleTrans',
                resize_lim=[1.0, 1.0],
                rot_lim=[0.0, 0.0],
                trans_lim=0.0,
                is_train=False),
            dict(
                type='LoadBEVSegmentation',
                dataset_root='data/nuscenes/',
                xbound=[-50.0, 50.0, 0.1],
                ybound=[-50.0, 50.0, 0.1],
                classes=[
                    'drivable_area', 'ped_crossing', 'walkway', 'stop_line',
                    'carpark_area', 'divider'
                ]),
            dict(
                type='PointsRangeFilter',
                point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]),
            dict(
                type='ImageNormalize',
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]),
            dict(
                type='DefaultFormatBundle3D',
                classes=[
                    'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                    'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                    'traffic_cone'
                ]),
            dict(
                type='Collect3D',
                keys=[
                    'img', 'points', 'gt_bboxes_3d', 'gt_labels_3d',
                    'gt_masks_bev'
                ],
                meta_keys=[
                    'camera_intrinsics', 'camera2ego', 'lidar2ego',
                    'lidar2camera', 'camera2lidar', 'lidar2image',
                    'img_aug_matrix', 'lidar_aug_matrix'
                ])
        ],
        object_classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        map_classes=[
            'drivable_area', 'ped_crossing', 'walkway', 'stop_line',
            'carpark_area', 'divider'
        ],
        modality=dict(
            use_lidar=True,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=False),
        test_mode=False,
        box_type_3d='LiDAR'),
    test=dict(
        type='NuScenesDataset',
        dataset_root='data/nuscenes/',
        ann_file='data/nuscenes/nuscenes_infos_val.pkl',
        pipeline=[
            dict(type='LoadMultiViewImageFromFiles', to_float32=True),
            dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=5,
                use_dim=5,
                reduce_beams=32,
                load_augmented=None),
            dict(
                type='LoadPointsFromMultiSweeps',
                sweeps_num=9,
                load_dim=5,
                use_dim=5,
                reduce_beams=32,
                pad_empty_sweeps=True,
                remove_close=True,
                load_augmented=None),
            dict(
                type='LoadAnnotations3D',
                with_bbox_3d=True,
                with_label_3d=True,
                with_attr_label=False),
            dict(
                type='ImageAug3D',
                final_dim=[256, 704],
                resize_lim=[0.48, 0.48],
                bot_pct_lim=[0.0, 0.0],
                rot_lim=[0.0, 0.0],
                rand_flip=False,
                is_train=False),
            dict(
                type='GlobalRotScaleTrans',
                resize_lim=[1.0, 1.0],
                rot_lim=[0.0, 0.0],
                trans_lim=0.0,
                is_train=False),
            dict(
                type='LoadBEVSegmentation',
                dataset_root='data/nuscenes/',
                xbound=[-50.0, 50.0, 0.1],
                ybound=[-50.0, 50.0, 0.1],
                classes=[
                    'drivable_area', 'ped_crossing', 'walkway', 'stop_line',
                    'carpark_area', 'divider'
                ]),
            dict(
                type='PointsRangeFilter',
                point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]),
            dict(
                type='ImageNormalize',
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]),
            dict(
                type='DefaultFormatBundle3D',
                classes=[
                    'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                    'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                    'traffic_cone'
                ]),
            dict(
                type='Collect3D',
                keys=[
                    'img', 'points', 'gt_bboxes_3d', 'gt_labels_3d',
                    'gt_masks_bev'
                ],
                meta_keys=[
                    'camera_intrinsics', 'camera2ego', 'lidar2ego',
                    'lidar2camera', 'camera2lidar', 'lidar2image',
                    'img_aug_matrix', 'lidar_aug_matrix'
                ])
        ],
        object_classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        map_classes=[
            'drivable_area', 'ped_crossing', 'walkway', 'stop_line',
            'carpark_area', 'divider'
        ],
        modality=dict(
            use_lidar=True,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=False),
        test_mode=True,
        box_type_3d='LiDAR'))
evaluation = dict(
    interval=1,
    pipeline=[
        dict(type='LoadMultiViewImageFromFiles', to_float32=True),
        dict(
            type='LoadPointsFromFile',
            coord_type='LIDAR',
            load_dim=5,
            use_dim=5,
            reduce_beams=32,
            load_augmented=None),
        dict(
            type='LoadPointsFromMultiSweeps',
            sweeps_num=9,
            load_dim=5,
            use_dim=5,
            reduce_beams=32,
            pad_empty_sweeps=True,
            remove_close=True,
            load_augmented=None),
        dict(
            type='LoadAnnotations3D',
            with_bbox_3d=True,
            with_label_3d=True,
            with_attr_label=False),
        dict(
            type='ImageAug3D',
            final_dim=[256, 704],
            resize_lim=[0.48, 0.48],
            bot_pct_lim=[0.0, 0.0],
            rot_lim=[0.0, 0.0],
            rand_flip=False,
            is_train=False),
        dict(
            type='GlobalRotScaleTrans',
            resize_lim=[1.0, 1.0],
            rot_lim=[0.0, 0.0],
            trans_lim=0.0,
            is_train=False),
        dict(
            type='LoadBEVSegmentation',
            dataset_root='data/nuscenes/',
            xbound=[-50.0, 50.0, 0.1],
            ybound=[-50.0, 50.0, 0.1],
            classes=[
                'drivable_area', 'ped_crossing', 'walkway', 'stop_line',
                'carpark_area', 'divider'
            ]),
        dict(
            type='PointsRangeFilter',
            point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]),
        dict(
            type='ImageNormalize',
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225]),
        dict(
            type='DefaultFormatBundle3D',
            classes=[
                'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                'traffic_cone'
            ]),
        dict(
            type='Collect3D',
            keys=[
                'img', 'points', 'gt_bboxes_3d', 'gt_labels_3d', 'gt_masks_bev'
            ],
            meta_keys=[
                'camera_intrinsics', 'camera2ego', 'lidar2ego', 'lidar2camera',
                'camera2lidar', 'lidar2image', 'img_aug_matrix',
                'lidar_aug_matrix'
            ])
    ])
model = dict(
    type='BEVFusion',
    heads=dict(
        object=None,
        map=dict(
            type='BEVSegmentationHead',
            in_channels=512,
            grid_transform=dict(
                input_scope=[[-51.2, 51.2, 0.8], [-51.2, 51.2, 0.8]],
                output_scope=[[-50, 50, 0.1], [-50, 50, 0.1]]),
            classes=[
                'drivable_area', 'ped_crossing', 'walkway', 'stop_line',
                'carpark_area', 'divider'
            ],
            loss='focal')),
    encoders=dict(
        camera=dict(
            backbone=dict(
                type='SwinTransformer',
                embed_dims=96,
                depths=[2, 2, 6, 2],
                num_heads=[3, 6, 12, 24],
                window_size=7,
                mlp_ratio=4,
                qkv_bias=True,
                qk_scale=None,
                drop_rate=0.0,
                attn_drop_rate=0.0,
                drop_path_rate=0.3,
                patch_norm=True,
                out_indices=[1, 2, 3],
                with_cp=False,
                convert_weights=True,
                init_cfg=dict(
                    type='Pretrained',
                    checkpoint='pretrained/swint-nuimages-pretrained.pth')),
            neck=dict(
                type='GeneralizedLSSFPN',
                in_channels=[192, 384, 768],
                out_channels=256,
                start_level=0,
                num_outs=3,
                norm_cfg=dict(type='BN2d', requires_grad=True),
                act_cfg=dict(type='ReLU', inplace=True),
                upsample_cfg=dict(mode='bilinear', align_corners=False)),
            vtransform=dict(
                type='LSSTransform',
                in_channels=256,
                out_channels=80,
                image_size=[256, 704],
                feature_size=[32, 88],
                xbound=[-51.2, 51.2, 0.4],
                ybound=[-51.2, 51.2, 0.4],
                zbound=[-10.0, 10.0, 20.0],
                dbound=[1.0, 60.0, 0.5],
                downsample=2)),
        lidar=dict(
            voxelize=dict(
                max_num_points=10,
                point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0],
                voxel_size=[0.1, 0.1, 0.2],
                max_voxels=[90000, 120000]),
            backbone=dict(
                type='SparseEncoder',
                in_channels=5,
                sparse_shape=[1024, 1024, 41],
                output_channels=128,
                order=['conv', 'norm', 'act'],
                encoder_channels=[[16, 16, 32], [32, 32, 64], [64, 64, 128],
                                  [128, 128]],
                encoder_paddings=[[0, 0, 1], [0, 0, 1], [0, 0, [1, 1, 0]],
                                  [0, 0]],
                block_type='basicblock'))),
    gating=None,
    fuser=dict(type='ConvFuser', in_channels=[80, 256], out_channels=256),
    decoder=dict(
        backbone=dict(
            type='SECOND',
            in_channels=256,
            out_channels=[128, 256],
            layer_nums=[5, 5],
            layer_strides=[1, 2],
            norm_cfg=dict(type='BN', eps=0.001, momentum=0.01),
            conv_cfg=dict(type='Conv2d', bias=False)),
        neck=dict(
            type='SECONDFPN',
            in_channels=[128, 256],
            out_channels=[256, 256],
            upsample_strides=[1, 2],
            norm_cfg=dict(type='BN', eps=0.001, momentum=0.01),
            upsample_cfg=dict(type='deconv', bias=False),
            use_conv_for_no_stride=True)))
optimizer = dict(
    type='AdamW',
    lr=0.0001,
    weight_decay=0.01,
    paramwise_cfg=dict(
        custom_keys=dict(
            absolute_pos_embed=dict(decay_mult=0),
            relative_position_bias_table=dict(decay_mult=0))))
optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))
lr_config = dict(policy='cyclic')
momentum_config = dict(policy='cyclic')
run_dir = 'runs/run-fb5b2bb4'

2024-02-16 10:33:16,875 - mmdet3d - INFO - Set random seed to 0, deterministic mode: False
.........Config path for training.............................. {'type': 'CBGSDataset', 'dataset': {'type': 'NuScenesDataset', 'dataset_root': 'data/nuscenes/', 'ann_file': 'data/nuscenes/nuscenes_infos_train.pkl', 'pipeline': [{'type': 'LoadMultiViewImageFromFiles', 'to_float32': True}, {'type': 'LoadPointsFromFile', 'coord_type': 'LIDAR', 'load_dim': 5, 'use_dim': 5, 'reduce_beams': 32, 'load_augmented': None}, {'type': 'LoadPointsFromMultiSweeps', 'sweeps_num': 9, 'load_dim': 5, 'use_dim': 5, 'reduce_beams': 32, 'pad_empty_sweeps': True, 'remove_close': True, 'load_augmented': None}, {'type': 'LoadAnnotations3D', 'with_bbox_3d': True, 'with_label_3d': True, 'with_attr_label': False}, {'type': 'ObjectPaste', 'stop_epoch': -1, 'db_sampler': {'dataset_root': 'data/nuscenes/', 'info_path': 'data/nuscenes/nuscenes_dbinfos_train.pkl', 'rate': 1.0, 'prepare': {'filter_by_difficulty': [-1], 'filter_by_min_points': {'car': 5, 'truck': 5, 'bus': 5, 'trailer': 5, 'construction_vehicle': 5, 'traffic_cone': 5, 'barrier': 5, 'motorcycle': 5, 'bicycle': 5, 'pedestrian': 5}}, 'classes': ['car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'], 'sample_groups': {'car': 2, 'truck': 3, 'construction_vehicle': 7, 'bus': 4, 'trailer': 6, 'barrier': 2, 'motorcycle': 6, 'bicycle': 6, 'pedestrian': 2, 'traffic_cone': 2}, 'points_loader': {'type': 'LoadPointsFromFile', 'coord_type': 'LIDAR', 'load_dim': 5, 'use_dim': 5, 'reduce_beams': 32}}}, {'type': 'ImageAug3D', 'final_dim': [256, 704], 'resize_lim': [0.38, 0.55], 'bot_pct_lim': [0.0, 0.0], 'rot_lim': [-5.4, 5.4], 'rand_flip': True, 'is_train': True}, {'type': 'GlobalRotScaleTrans', 'resize_lim': [0.9, 1.1], 'rot_lim': [-0.78539816, 0.78539816], 'trans_lim': 0.5, 'is_train': True}, {'type': 'LoadBEVSegmentation', 'dataset_root': 'data/nuscenes/', 'xbound': [-50.0, 50.0, 0.1], 'ybound': [-50.0, 50.0, 0.1], 'classes': ['drivable_area', 'ped_crossing', 'walkway', 'stop_line', 'carpark_area', 'divider']}, {'type': 'RandomFlip3D'}, {'type': 'PointsRangeFilter', 'point_cloud_range': [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]}, {'type': 'ObjectRangeFilter', 'point_cloud_range': [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]}, {'type': 'ObjectNameFilter', 'classes': ['car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone']}, {'type': 'ImageNormalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, {'type': 'GridMask', 'use_h': True, 'use_w': True, 'max_epoch': 20, 'rotate': 1, 'offset': False, 'ratio': 0.5, 'mode': 1, 'prob': 0.0, 'fixed_prob': True}, {'type': 'PointShuffle'}, {'type': 'DefaultFormatBundle3D', 'classes': ['car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone']}, {'type': 'Collect3D', 'keys': ['img', 'points', 'gt_bboxes_3d', 'gt_labels_3d', 'gt_masks_bev'], 'meta_keys': ['camera_intrinsics', 'camera2ego', 'lidar2ego', 'lidar2camera', 'camera2lidar', 'lidar2image', 'img_aug_matrix', 'lidar_aug_matrix']}], 'object_classes': ['car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'], 'map_classes': ['drivable_area', 'ped_crossing', 'walkway', 'stop_line', 'carpark_area', 'divider'], 'modality': {'use_lidar': True, 'use_camera': True, 'use_radar': False, 'use_map': False, 'use_external': False}, 'test_mode': False, 'use_valid_flag': True, 'box_type_3d': 'LiDAR'}}
2024-02-16 10:33:30,651 - mmdet3d - INFO - load 65262 truck database infos
2024-02-16 10:33:30,651 - mmdet3d - INFO - load 161928 pedestrian database infos
2024-02-16 10:33:30,651 - mmdet3d - INFO - load 339949 car database infos
2024-02-16 10:33:30,651 - mmdet3d - INFO - load 2120 movable_object.debris database infos
2024-02-16 10:33:30,651 - mmdet3d - INFO - load 62964 traffic_cone database infos
2024-02-16 10:33:30,651 - mmdet3d - INFO - load 8846 motorcycle database infos
2024-02-16 10:33:30,651 - mmdet3d - INFO - load 2259 static_object.bicycle_rack database infos
2024-02-16 10:33:30,651 - mmdet3d - INFO - load 19195 movable_object.pushable_pullable database infos
2024-02-16 10:33:30,651 - mmdet3d - INFO - load 11 vehicle.emergency.ambulance database infos
2024-02-16 10:33:30,651 - mmdet3d - INFO - load 11050 construction_vehicle database infos
2024-02-16 10:33:30,651 - mmdet3d - INFO - load 19202 trailer database infos
2024-02-16 10:33:30,651 - mmdet3d - INFO - load 107507 barrier database infos
2024-02-16 10:33:30,651 - mmdet3d - INFO - load 8185 bicycle database infos
2024-02-16 10:33:30,651 - mmdet3d - INFO - load 12286 bus database infos
2024-02-16 10:33:30,651 - mmdet3d - INFO - load 498 vehicle.emergency.police database infos
2024-02-16 10:33:30,651 - mmdet3d - INFO - load 751 human.pedestrian.stroller database infos
2024-02-16 10:33:30,651 - mmdet3d - INFO - load 619 animal database infos
2024-02-16 10:33:30,651 - mmdet3d - INFO - load 492 human.pedestrian.wheelchair database infos
2024-02-16 10:33:30,651 - mmdet3d - INFO - load 352 human.pedestrian.personal_mobility database infos
dict_items([('car', 5), ('truck', 5), ('bus', 5), ('trailer', 5), ('construction_vehicle', 5), ('traffic_cone', 5), ('barrier', 5), ('motorcycle', 5), ('bicycle', 5), ('pedestrian', 5)])
car 5
truck 5
bus 5
trailer 5
construction_vehicle 5
traffic_cone 5
barrier 5
motorcycle 5
bicycle 5
pedestrian 5
2024-02-16 10:33:32,504 - mmdet3d - INFO - After filter database:
2024-02-16 10:33:32,506 - mmdet3d - INFO - load 51854 truck database infos
2024-02-16 10:33:32,508 - mmdet3d - INFO - load 122405 pedestrian database infos
2024-02-16 10:33:32,508 - mmdet3d - INFO - load 214084 car database infos
2024-02-16 10:33:32,508 - mmdet3d - INFO - load 2120 movable_object.debris database infos
2024-02-16 10:33:32,508 - mmdet3d - INFO - load 39825 traffic_cone database infos
2024-02-16 10:33:32,508 - mmdet3d - INFO - load 6584 motorcycle database infos
2024-02-16 10:33:32,508 - mmdet3d - INFO - load 2259 static_object.bicycle_rack database infos
2024-02-16 10:33:32,508 - mmdet3d - INFO - load 19195 movable_object.pushable_pullable database infos
2024-02-16 10:33:32,508 - mmdet3d - INFO - load 11 vehicle.emergency.ambulance database infos
2024-02-16 10:33:32,508 - mmdet3d - INFO - load 9803 construction_vehicle database infos
2024-02-16 10:33:32,508 - mmdet3d - INFO - load 16770 trailer database infos
2024-02-16 10:33:32,508 - mmdet3d - INFO - load 87434 barrier database infos
2024-02-16 10:33:32,508 - mmdet3d - INFO - load 5984 bicycle database infos
2024-02-16 10:33:32,508 - mmdet3d - INFO - load 10100 bus database infos
2024-02-16 10:33:32,509 - mmdet3d - INFO - load 498 vehicle.emergency.police database infos
2024-02-16 10:33:32,509 - mmdet3d - INFO - load 751 human.pedestrian.stroller database infos
2024-02-16 10:33:32,509 - mmdet3d - INFO - load 619 animal database infos
2024-02-16 10:33:32,509 - mmdet3d - INFO - load 492 human.pedestrian.wheelchair database infos
2024-02-16 10:33:32,509 - mmdet3d - INFO - load 352 human.pedestrian.personal_mobility database infos
[80, 256] 256
2024-02-16 10:33:34,903 - mmdet - INFO - load checkpoint from local path: pretrained/swint-nuimages-pretrained.pth
2024-02-16 10:33:34,991 - mmdet - INFO - load checkpoint from local path: pretrained/swint-nuimages-pretrained.pth
2024-02-16 10:33:35,060 - mmdet3d - INFO - Model:
BEVFusion(
  (encoders): ModuleDict(
    (camera): ModuleDict(
      (backbone): SwinTransformer(
        (patch_embed): PatchEmbed(
          (adap_padding): AdaptivePadding()
          (projection): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_after_pos): Dropout(p=0.0, inplace=False)
        (stages): ModuleList(
          (0): SwinBlockSequence(
            (blocks): ModuleList(
              (0): SwinBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=96, out_features=288, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=96, out_features=96, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=96, out_features=384, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=384, out_features=96, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
              (1): SwinBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=96, out_features=288, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=96, out_features=96, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=96, out_features=384, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=384, out_features=96, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
            )
            (downsample): PatchMerging(
              (adap_padding): AdaptivePadding()
              (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))
              (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (reduction): Linear(in_features=384, out_features=192, bias=False)
            )
          )
          (1): SwinBlockSequence(
            (blocks): ModuleList(
              (0): SwinBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=192, out_features=576, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=192, out_features=192, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=192, out_features=768, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=768, out_features=192, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
              (1): SwinBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=192, out_features=576, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=192, out_features=192, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=192, out_features=768, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=768, out_features=192, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
            )
            (downsample): PatchMerging(
              (adap_padding): AdaptivePadding()
              (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))
              (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (reduction): Linear(in_features=768, out_features=384, bias=False)
            )
          )
          (2): SwinBlockSequence(
            (blocks): ModuleList(
              (0): SwinBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=384, out_features=1152, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=384, out_features=384, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=384, out_features=1536, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=1536, out_features=384, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
              (1): SwinBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=384, out_features=1152, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=384, out_features=384, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=384, out_features=1536, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=1536, out_features=384, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
              (2): SwinBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=384, out_features=1152, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=384, out_features=384, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=384, out_features=1536, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=1536, out_features=384, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
              (3): SwinBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=384, out_features=1152, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=384, out_features=384, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=384, out_features=1536, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=1536, out_features=384, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
              (4): SwinBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=384, out_features=1152, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=384, out_features=384, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=384, out_features=1536, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=1536, out_features=384, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
              (5): SwinBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=384, out_features=1152, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=384, out_features=384, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=384, out_features=1536, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=1536, out_features=384, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
            )
            (downsample): PatchMerging(
              (adap_padding): AdaptivePadding()
              (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))
              (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
              (reduction): Linear(in_features=1536, out_features=768, bias=False)
            )
          )
          (3): SwinBlockSequence(
            (blocks): ModuleList(
              (0): SwinBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=768, out_features=2304, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=768, out_features=768, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=768, out_features=3072, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=3072, out_features=768, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
              (1): SwinBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=768, out_features=2304, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=768, out_features=768, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=768, out_features=3072, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=3072, out_features=768, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
            )
          )
        )
        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      init_cfg={'type': 'Pretrained', 'checkpoint': 'pretrained/swint-nuimages-pretrained.pth'}
      (neck): GeneralizedLSSFPN(
        (lateral_convs): ModuleList(
          (0): ConvModule(
            (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
          (1): ConvModule(
            (conv): Conv2d(1152, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
        )
        (fpn_convs): ModuleList(
          (0): ConvModule(
            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
          (1): ConvModule(
            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
        )
      )
      (vtransform): LSSTransform(
        (depthnet): Conv2d(256, 198, kernel_size=(1, 1), stride=(1, 1))
        (downsample): Sequential(
          (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (4): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (7): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (8): ReLU(inplace=True)
        )
      )
    )
    (lidar): ModuleDict(
      (voxelize): Voxelization(voxel_size=[0.1, 0.1, 0.2], point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0], max_num_points=10, max_voxels=(90000, 120000), deterministic=True)
      (backbone): SparseEncoder(
        (conv_input): SparseSequential(
          (0): SubMConv3d()
          (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (encoder_layers): SparseSequential(
          (encoder_layer1): SparseSequential(
            (0): SparseBasicBlock(
              (conv1): SubMConv3d()
              (bn1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (conv2): SubMConv3d()
              (bn2): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
            )
            (1): SparseBasicBlock(
              (conv1): SubMConv3d()
              (bn1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (conv2): SubMConv3d()
              (bn2): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
            )
            (2): SparseSequential(
              (0): SparseConv3d()
              (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
          )
          (encoder_layer2): SparseSequential(
            (0): SparseBasicBlock(
              (conv1): SubMConv3d()
              (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (conv2): SubMConv3d()
              (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
            )
            (1): SparseBasicBlock(
              (conv1): SubMConv3d()
              (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (conv2): SubMConv3d()
              (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
            )
            (2): SparseSequential(
              (0): SparseConv3d()
              (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
          )
          (encoder_layer3): SparseSequential(
            (0): SparseBasicBlock(
              (conv1): SubMConv3d()
              (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (conv2): SubMConv3d()
              (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
            )
            (1): SparseBasicBlock(
              (conv1): SubMConv3d()
              (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (conv2): SubMConv3d()
              (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
            )
            (2): SparseSequential(
              (0): SparseConv3d()
              (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
          )
          (encoder_layer4): SparseSequential(
            (0): SparseBasicBlock(
              (conv1): SubMConv3d()
              (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (conv2): SubMConv3d()
              (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
            )
            (1): SparseBasicBlock(
              (conv1): SubMConv3d()
              (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (conv2): SubMConv3d()
              (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
            )
          )
        )
        (conv_out): SparseSequential(
          (0): SparseConv3d()
          (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
    )
  )
  (fuser): ConvFuser(
    (0): Conv2d(336, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (decoder): ModuleDict(
    (backbone): SECOND(
      (blocks): ModuleList(
        (0): Sequential(
          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (7): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (8): ReLU(inplace=True)
          (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (10): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (11): ReLU(inplace=True)
          (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (13): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (14): ReLU(inplace=True)
          (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (16): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (17): ReLU(inplace=True)
        )
        (1): Sequential(
          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (7): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (8): ReLU(inplace=True)
          (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (10): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (11): ReLU(inplace=True)
          (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (13): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (14): ReLU(inplace=True)
          (15): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (16): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (17): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}
    (neck): SECONDFPN(
      (deblocks): ModuleList(
        (0): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (1): Sequential(
          (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
    )
    init_cfg=[{'type': 'Kaiming', 'layer': 'ConvTranspose2d'}, {'type': 'Constant', 'layer': 'NaiveSyncBatchNorm2d', 'val': 1.0}]
  )
  (heads): ModuleDict(
    (map): BEVSegmentationHead(
      (transform): BEVGridTransform()
      (classifier): Sequential(
        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
        (6): Conv2d(512, 6, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
)
